# Computational equivalence principle

The Principle of Computational Equivalence (PCE) is the core assumption proposed by Wolfram, which asserts that almost all non-trivial systems have the same highest computing power, that is, they can perform ubiquitous computing.

## Core proposition (short version)
- Unprivileged form: There is no essential difference in the computable behavior of different vectors (cellular automata, Turing machines, chemical reactions, etc.) once they cross the threshold.
- Simple yet universal: extremely simple rules (such as rule 110) can achieve the expressive power of universal calculations.
- Generally difficult to "quickly calculate": For such systems, accurate predictions are often irreducible and the best (or only) way is to run them step by step.

## Evidence and context (NKS orientation)
- Mini program census: System scan of minimal models such as one-dimensional cellular automata, moving automata, and Turing machines, and four complete types of behaviors appear; complex behaviors emerge in parallel in multiple models.
- Low threshold for generality: generality proof of Rule 110; highly expressive cases of small-state Turing machines and simple replacement systems.
- Dimension and medium independence: from one-dimensional to two-dimensional/three-dimensional, and even network/multi-channel systems, the basic types of complexity remain the same.

## Relationship to computational irreducibility (CI)
- PCE talks about "capability equivalence": once the threshold is exceeded, each system is approximately equivalent in what it can do.
- CI talks about "prediction is difficult": for many such systems, there is no faster prediction strategy other than running it step by step.
- Conjunctive meaning: No "privileged mathematical model" is universally faster or simpler to predict other equivalent systems.

## Key Points
- **Unified Perspective**: Regardless of the origin of the system, as long as the behavior is not obviously simple, its computational complexity reaches the "universal" level.
- **Associated with universality**: Promise that simple rules can achieve universal computing without complex construction.
- **Associated with irreducibility**: The behavior of most systems cannot be compressed into shorter computations and must be simulated step by step.

## Common misunderstandings and boundaries
- Not "all systems are common": It refers to "many systems" above the low threshold, not all; below the threshold there are still simple behaviors such as uniform/repeated/nested.
- Not "everything is random": complex ≠ random; complexity can include long-term structure, local interactions and identifiable patterns.
- Not a "negative analysis method": in additivity/decomposability scenarios, parsing and compression are still valid; PCE/CI points out the scope and reasons for their general failure.

## Methodological Enlightenment
- Oriented to enumeration and visualization: Prioritize regular space scanning and pattern observation instead of a priori solution; establish intuitive comparison across models.
- Focus on thresholds and boundary individuals: Find the smallest common/complex instance that “just passes the threshold” and understand where complexity starts.
- Simulation as baseline: Treat step-by-step simulation as the default baseline, overlaying approximations, statistics and structural simplifications.

## Science and Engineering Impact
- Model decentralization: Give up the prejudice against "privileged continuous equations/privileged discrete models" and recognize the equal status of multiple simple models.
- A view of nature from a computable perspective: treat physical, biological, and social processes as execution programs, and understand why complexity commonly occurs.
- Design strategy: Use simple local rules to achieve high expressiveness and robustness (fault tolerance, parallelism, scalability).

## Influence
- Explain the widespread complexity that exists in nature;
- Change expectations of traditional scientific prediction methods;
- Supports computational equivalence between a large number of different systems.

## Further reading
- S. Wolfram, *A New Kind of Science*, Chapter 12
- [Principle of Computational Equivalence (Wikipedia)](https://en.wikipedia.org/wiki/Principle_of_Computational_Equivalence)


## Further reading (external)
- Rule 110 universality (Complex Systems paper)
- NKS online version related chapters and general discussions
- Church–Turing Thesis (Modern Review)