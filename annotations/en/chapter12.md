Chapter 12: Principle of Computational Equivalence

The last chapter is the philosophical climax of the entire book. It synthesizes the findings of the previous eleven chapters into a single, overarching principle, which Wolfram proposes as a new law of nature: the Principle of Computational Equivalence (PCE). 25

This chapter begins by formalizing any process that obeys deterministic rules, whether in a man-made device or in nature, as a computation. 60 This universal perspective allows the formulation of principles applicable to all systems. PCE can be stated in many ways, but its core claim is that almost all processes that are not obviously simple are computationally equivalent in complexity. 61

This means that there is no infinite hierarchy of computing power. One might have thought that as system structures became more complex, they would be able to perform increasingly complex calculations. PCE claims this is wrong. Instead, it assumes that once a certain very low complexity threshold is crossed, a system reaches the highest level of computational power—universality—and that no system, no matter how complex its rules, can be fundamentally more powerful. 60 All such systems are equivalent in computational power.

The proof of universality of Rule 110 is key empirical evidence for this principle. If a system with such simple rules can achieve maximum computational complexity, it strongly suggests that this level is not difficult to achieve and is likely to be ubiquitous. 59 PCE means that systems with general computing capabilities are ubiquitous in nature. This means that processes such as the evolution of weather systems, the functioning of the human brain, and the dynamics of simple cellular automata all perform the same complex computations at a fundamental level. 55

Several profound implications derive from this core principle:
Computational Irreducibility: If a system is performing computations as complex as any general-purpose computer, it is impossible to "beat" it with another system. This means that there can be no universal shortcuts or predictive formulas for a system's behavior. The only way to understand the results of its evolution is to run the process itself step-by-step. This is computational irreducibility, and PCE means that it is a universal feature of any system whose behavior is not obviously simple. 63 This sets a fundamental limit on the predictive power of science.
The Nature of Intelligence: PCE challenges the idea that human intelligence is somehow special or occupies the pinnacle of computational complexity. It shows that our thought processes are computationally equivalent to many other processes found in nature and the computational universe. This does not mean that the weather system is "thinking," but rather that it performs intrinsic computational work as complex as the computational work that underlies our minds. 62
Determinism and Free Will: This principle provides a way to reconcile the apparent conflict between a deterministic universe governed by fixed laws and the experience of free will. Even if the underlying rules are simple and deterministic, computational irreducibility means that the consequences of these rules are fundamentally unpredictable in practice. Our experience of "choice" or "free will" can be thought of as our inability to predict the irreducible computational consequences of our own thought processes before they actually occur. 55
In summary, the principle of computational equivalence is regarded as the intellectual cornerstone of the "new science". It is a statement about the fundamental nature of computation, a proposed law of nature, and a redefinition of our place in the universe. It suggests that we are not computationally superior observers looking down on a simple, predictable world from above, but rather we are ourselves computationally equivalent participants in a universe filled with irreducible and complex computations.